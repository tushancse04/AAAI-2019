\begin{abstract}
Lifted inference has become the predominant approach to scaling up inference in Markov Logic Networks (MLNs). The main challenge with lifted inference methods is to find symmetries in the MLN. Though there has been a considerable amount of work over the last several years in computing symmetries for MLNs, exploiting approximate symmetries to its fullest possible extent is a challenging task. In this paper, we present a novel approach for symmetry detection based on a neural embedding for objects in the MLN, which we call Obj2vec. Specifically, Obj2vec embeds objects in a low-dimensional space, where symmetric objects are placed close together in this space. Our approach is particularly useful, since it does not require difficult-to-compute features for detecting symmetries, and more importantly it takes advantage of joint dependencies across multiple domains to detect more complex symmetries than is possible if we treat domains independently. Our experiments on several real-world benchmarks validate our hypothesis, and show that Obj2vec-based lifted inference is accurate, scalable and effective in detecting symmetries.
\end{abstract}