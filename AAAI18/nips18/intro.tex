\section{Introduction}

Markov Logic Networks (MLNs)~\cite{domingos&lowd09} are well-known statistical relational models with intuitive semantics and powerful expressiveness. Specifically, MLNs represent both relational concepts as well as uncertainty using weighted first-order logic formulas. An MLN is a template for Markov networks, i.e., we can instantiate an MLN with objects from a real-world domain and generate Markov networks which represent probability distribution over relational worlds of the MLN. A key challenge with MLNs, as is now well-known, is to develop scalable inference methods for them.  In this regard, the idea of {\em lifted} inference has been a major advancement, where the idea is to utilize symmetries that exist in the MLN due to its template structure, in order to improve scalability of inference.

However, identifying symmetries in the MLN efficiently and effectively is non-trivial. Specifically, the Markov network representing the MLN distribution is usually very large, and it is often intractable to try to process the MLN directly using its underlying Markov network representation. Therefore, several previously developed lifted inference methods try to process the MLN without creating its {\em ground} Markov network. For instance, popular exact lifted inference methods such as FOVE~\cite{braz07}, PTP~\cite{gogate&domingos11b} and WKBMC~\cite{broeck&al11} develop {\em lifting} rules which identify symmetries in the MLN directly from the first-order structure of its formulas. Similarly, several lifted approaches have been proposed for approximate inference by utilizing symmetries within MCMC\cite{niepert12,venugopal&gogate12}, belief propagation~\cite{singla&domingos08,ahmadi&al13}, etc.

Unfortunately, it turns out that exact symmetries required for lifted inference are usually absent in real-world MLNs. Therefore, a relatively new direction has been to use approximate symmetries to perform lifted inference in a scalable manner on real-world MLNs. Broeck and Darwiche~\cite{broeck&darwiche13} proposed a boolean factorization approach to approximate binary evidence with evidence that has more symmetries, which makes lifting easier. Venugopal and Gogate~\cite{venugopal&gogate14} proposed a pre-processing method that clusters each domain using algorithms such as K-Means, and then replaces a cluster by its cluster-center. However, there are some key issues with these approximate lifting methods. First, clustering methods such as K-Means requires feature-engineering. For example, Venugopal and Gogate use features based on counts of formulas satisfied by the evidence. Such features need to accurately encode symmetry in the MLN. Second, joint dependencies between across domains in the MLN are not fully considered while learning the approximate symmetries. For example, consider an MLN that analyzes restaurant reviews. The likelihood of symmetry between two distinct reviews increases if the reviews are written for restaurants that have symmetry. At the same time,  restaurants that are somewhat similar may elicit reviews that have a higher likelihood of symmetries. Our main contribution in this paper is to significantly advance the state-of-the-art in detecting approximate symmetries in MLNs by using neural embeddings. Two key advantages of our approach include, it does not use any hand-coded features, and it takes advantage of joint dependencies across domains to detect symmetries more effectively.

Our approach is based on the premise that objects that have similar contexts in the MLN formulas exhibit symmetries. For example, consider once again, the domain of reviews written for restaurants. If, in the ground formulas of the MLN, whenever a ground formula containing review $R_1$ is true, and a ground formula containing review $R_2$ is true, if the other objects in the ground formulas such as restaurants, users, etc. (which forms the context for $R_1$ and $R_2$) are symmetric, then it is likely that $R_1$ and $R_2$ are also symmetric. To detect such symmetries, we develop a novel model similar to the popular skip-gram models (such as Word2vec) which we call Obj2vec model. Obj2vec encodes the context in which objects appear in a ground formula of the MLN that is satisfied by the observed evidence, as ``sentences'', and then generates a low-dimensional embedding for these objects. Objects that have similar contexts will be close to each other in the embedded vector-space, and are therefore considered as approximately symmetric to each other. We reduce the total number of objects in the domains of the MLN by removing a subset of objects whose vectors are close to the vectors of objects that we retain in the MLN. As is the case with previous approaches~\cite{broeck&darwiche13,venugopal&gogate14}, since our approach is a pre-processing method on the MLN, it can be applied to scale-up any existing inference algorithm.


%Thus, if two objects (corresponding to possibly different domains) share a common formula, since these objects appear together in a similar context in the MLN, our encoding places them close to each other in the document. This has the effect that distinct objects of a domain that appear in a common context are likely to be symmetrical to each other since they interact with similar objects. We then use Word2vec to vectorize each object, where distinct objects that consistently appear in similar contexts are likely to be close to each other in the vector space. We reduce the total number of objects in the MLN by removing a subset of objects whose vectors are close to the vectors of objects retained in the MLN. Since our approach is a pre-processing method, it can be applied to scale-up any inference algorithm.

We perform experiments on three real-world datasets taken from Alchemy~\cite{kok&al06}, namely, Webkb for collective classification, Cora for entity resolution, and protein interaction. Further, to illustrate the value of our approach in detecting symmetries, we use a dataset containing Yelp reviews from restaurants. We show that our approach significantly outperforms existing approaches and is effective in detecting symmetries from context.






